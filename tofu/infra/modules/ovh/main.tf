#############################################
# OVH Core Module
# - Creates a Managed Kubernetes cluster
# - Optionally creates two S3-compatible buckets used by Restate
#############################################
terraform {
  required_providers {
    ovh = {
      source  = "registry.opentofu.org/ovh/ovh"
      version = ">= 2.6.0"
    }
  }
}

# Inputs
variable "project" { type = string }
variable "environment" { type = string }
variable "project_id" { type = string }
variable "region" { type = string }
variable "k8s_version" { type = string }
variable "cluster_name" { type = string }
variable "node_flavor" { type = string }
variable "nodepool_size" { type = number }
variable "nodepool_autoscale" { type = bool }
variable "nodepool_min" { type = number }
variable "nodepool_max" { type = number }
variable "vrack" { type = bool }
variable "create_buckets" { type = bool }
variable "bucket_region" { type = string }
variable "vrack_vlan_id" {
  type        = number
  description = "vRack VLAN ID for the private network"
}
variable "private_subnet_cidr" {
  type        = string
  description = "CIDR for the private subnet (e.g., 10.42.0.0/24)"
}
variable "private_subnet_start" {
  type        = string
  description = "DHCP start IP for the subnet"
}
variable "private_subnet_end" {
  type        = string
  description = "DHCP end IP for the subnet"
}

locals {
  prefix = "${var.project}-${var.environment}"
}


# vRack private network (optional)
resource "ovh_cloud_project_network_private" "network" {
  count        = var.vrack ? 1 : 0
  service_name = var.project_id
  vlan_id      = var.vrack_vlan_id
  name         = "${local.prefix}-private"
  regions      = [var.region]
}

resource "ovh_cloud_project_network_private_subnet" "subnet" {
  count        = var.vrack ? 1 : 0
  service_name = var.project_id
  network_id   = ovh_cloud_project_network_private.network[0].id
  region       = var.region
  start        = var.private_subnet_start
  end          = var.private_subnet_end
  network      = var.private_subnet_cidr
  dhcp         = true
  no_gateway   = false
}

resource "ovh_cloud_project_gateway" "gateway" {
  count        = var.vrack ? 1 : 0
  service_name = var.project_id
  name         = "${local.prefix}-gw"
  model        = "s"
  region       = var.region
  network_id   = tolist(ovh_cloud_project_network_private.network[0].regions_attributes[*].openstackid)[0]
  subnet_id    = ovh_cloud_project_network_private_subnet.subnet[0].id
}


# Kubernetes cluster
# NOTE: OVH provider resource names based on upstream docs. Adjust if provider schema changes.
resource "ovh_cloud_project_kube" "this" {
  service_name = var.project_id
  region       = var.region
  name         = var.cluster_name
  version      = var.k8s_version

  # vRack attachment is usually managed via additional resources; keep flag for future wiring
  private_network_id = var.vrack ? tolist(ovh_cloud_project_network_private.network[0].regions_attributes[*].openstackid)[0] : null
  nodes_subnet_id    = var.vrack ? ovh_cloud_project_network_private_subnet.subnet[0].id : null

  dynamic "private_network_configuration" {
    for_each = var.vrack ? [1] : []
    content {
      # Use subnet DHCP gateway by setting empty string
      default_vrack_gateway              = ""
      private_network_routing_as_default = false
    }
  }
}

resource "ovh_cloud_project_kube_nodepool" "default" {
  service_name = var.project_id
  kube_id      = ovh_cloud_project_kube.this.id
  name         = "${local.prefix}-pool"
  flavor_name  = var.node_flavor
  desired_nodes = var.nodepool_size

  autoscale     = var.nodepool_autoscale
  min_nodes     = var.nodepool_min
  max_nodes     = var.nodepool_max
}

# Kubeconfig fetch
# The OVH API returns a kubeconfig content via separate data-source/resource call.
# Use the credentials resource to download admin config.
locals {
  # Provider exposes kubeconfig directly on the cluster resource
  kubeconfig_decoded = ovh_cloud_project_kube.this.kubeconfig
}

# Object Storage (S3) buckets â€” optional
# OVH has multiple object storage offerings; use Public Cloud Object Storage (S3-compatible).
# Bucket creation via API uses 'ovh_cloud_project_region_storage' and 'ovh_cloud_project_region_storage_user' in some versions.
# To keep this simple and portable, create two buckets via a generic S3 provider is not feasible here without credentials.
# We'll declare names as outputs so bucket creation can be handled externally if not supported in current provider.

output "cluster_id" { value = ovh_cloud_project_kube.this.id }
output "kubeconfig_decoded" {
  value     = local.kubeconfig_decoded
  sensitive = true
}
output "nodepool_id" { value = ovh_cloud_project_kube_nodepool.default.id }
output "bucket_meta_name" { value = "${local.prefix}-restate-meta" }
output "bucket_snapshots_name" { value = "${local.prefix}-restate-snapshots" }

output "private_network_id" {
  value = var.vrack ? tolist(ovh_cloud_project_network_private.network[0].regions_attributes[*].openstackid)[0] : null
}
output "private_subnet_id" {
  value = var.vrack ? ovh_cloud_project_network_private_subnet.subnet[0].id : null
}
output "gateway_id" {
  value = var.vrack ? ovh_cloud_project_gateway.gateway[0].id : null
}
